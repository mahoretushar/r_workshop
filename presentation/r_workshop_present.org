#   ____       ____                                                _
#  |  _ \     |  _ \ _ __ ___   __ _ _ __ __ _ _ __ ___  _ __ ___ (_)_ __   __ _
#  | |_) |____| |_) | '__/ _ \ / _` | '__/ _` | '_ ` _ \| '_ ` _ \| | '_ \ / _` |
#  |  _ <_____|  __/| | | (_) | (_| | | | (_| | | | | | | | | | | | | | | | (_| |
#  |_| \_\    |_|   |_|  \___/ \__, |_|  \__,_|_| |_| |_|_| |_| |_|_|_| |_|\__, |
#                              |___/                                       |___/

#+TITLE: *Machine Learning & Data Science with R*
#+AUTHOR: Prof. T. R. Mahore
#+DATE: April 11 2021 to April 18 2021

* Contents

1. Machine Learning and Data Science Introduction
2. Hand's on R - Programming for Machine Learning and Data Science
3. Machine learning fundamentals
4. Data visualization with R
5. Applied Statistics for Machine learning
6. Machine learning fundamentals (Models)
7. ANOVA with R
8. Linear Regression with R
9. Logistic Regression with R
10. Dimension reduction technique
11. Clustering with K-Means
12. Tree based models- CART & Random Forest
13. KNN- K Nearest Model
14. Naive Bayes
15. Neural Networks with R

* Machine Learning and Data Science Introduction
** Course Structure

1. R - Tool
2. Data Visualisation
3. Fundamentals of Applied Stastics
4. Machine Learning Fundamentals

** Machine Learning and Data Science in Scope

1. Machine Learning Fundamentals like supervised machine learnin, unsupervised machine learning etc.

2. R Programming Language - Fundamentals of R, data selection & manipulation with R, handling missiong values in R

3. Reading various files in R

4. Data visualization in R - Base functions to create bar plots, histograms, plots with libraries like ggplot2, maps, scatter3d plot & lattice

5. Applied statistics for machine Learning - descriptive analysis vs inferial analysis, t-test, confidence interval, standard error, standard deviation, varance, hypothesis testing and more

6. Linear Regression with R

7. Logistic Regression with R

8. Dimension Reduction techniques covering PCA

9. Clustering fundamentals with implementation of k-means in R

10. Tree based machine learning techniques like CART and Random Forest

11. KNN Implementation in R

12. Naive Bayes in R

13. Neural Network in R

** Data Science Help

- To University Forum - http://www.topuniversityforum.in/forums/artificial-intelligence-machine-learning.47/

- Stack Overflow - https://stackoverflow.com/

- GOOGLE

#+ATTR_HTML: :width 500px
[[file:img_1.png]]

** Data Science as Career

Data Driven Managers, Digital Marketing, Machine Learning, Deep Learning, Deep Learning and Artificial Intelligence

*** Portfolio

   a. Personal website/blog
   b. Github - https://github.com
   c. Linkedin

*** How to make right decision for your career in data science and machine learning

   This is one of the most important decision for you and you should use following factors to determine he right choice

   a. Job Profile Relevance - Exact Match, Partial Match, No Match

   b. Job Experience and Current Position

   c. Passion or Need

   d. Other Resources like Time and Money you can spend to learn New Skills

*** Business Analytics

   Businiss analytics is a field dedicated to make data driven decisions based on current and past data. It is closely related to business intelligence also. Both fields are essential but closely related so if you are looking for job and have experience in either of fields, you can easily cross over to others.

   People in this field hardly code and they primarily use tool's like Microsoft Excel, Tableau etc. These tool's generate Reports which are used for *BA* or *BI*

*** Machine Learning Engineer

   - You will find openings with Title *Machien Learning Engineer*

   - Job responsibilities are largly technical side of *Data Science* and need expertise in *R, SQL, PYTHON* etc.

*** Data Scientist

   - As per HBR *"Sexiest Job of 21st Century"*

   - It's a broad term including all kind of roles related to data science *(AI, ML, DL)*

   - Actual role and responsibilities could be far more specific like domain experts, programmer (R or Python), tool expert like Tableau or SPSS. Role is much into *Data Analysis* with technology sorrounding it

** Machine Learning Fundamentals

Let's Dive

*** Artificial Intelligence (AI)

- It is the higher umbrella category covering all aspect of the space where machines are expected to use intelligence for decision making

- *IBM Watson* is a common example of AI Tool

- It encompasses machine learning and Deep Learning Fields

- In reality, artificial intelligence is a broad field which has been derived from Math, Computer Science, Neuroscience and Artificial Psychology

*** Machine Learning

#+ATTR_HTML: :width 300px
[[file:img_2.png]]

- *Machine Learning* is the application of Artificial Intelligence

- Machine Learning is a Subset of AI

- Machine Learning use stastical analysis to deliver results

- In Machine Learning, you define the *Features* you need to make *Predictions* or to perform a task like E-mail Classification

*** Deep Learning

#+ATTR_HTML: :width 250px
[[file:img_3.png]]

- Deep learning takes the automation a step ahead and you don't need to define the features

- It is practically a subset of *Machine Learning* and but different from the rest of the algorithms

- It is inspired by neuron and attempt is to make artificial neurons mimicking human neurons

*** ML vs DL

|-------------------------------------------+--------------------------------------------|
| *Machine Learning*                          | *Deep Learning*                              |
|-------------------------------------------+--------------------------------------------|
| Need lesser data than Deep Learning       | Need more data                             |
|-------------------------------------------+--------------------------------------------|
| Can work with CPU                         | Needs GPU for optimum performance          |
|-------------------------------------------+--------------------------------------------|
| Need to manually define the features      | System can automatically figure that out   |
|-------------------------------------------+--------------------------------------------|
| Good & Recommended when you need to       | Recommended when your focus is on output,  |
| control feature defination and recreation | and not on ability to define feature but   |
|                                           | is not recommended when feature defination |
|                                           | is important                               |
|-------------------------------------------+--------------------------------------------|

*** Type of Machine Learning

 1. Supervised Machine Learning

    In all types of machine learning algorithm, you train your code with existing data. If this data is Labeled and have details about the properties of data, it is called *Supervised Machine Learning*, you train your data with labeled data and then compare the results. For example, you are developing a algorithm to automatically detect Spam Emails. Non Spam Emails are called ham. So in this case, you will create a dataset with information on spam and ham emails, something like this:

    |----------------------+------------------------------|
    | *Spam*                 | *Ham*                          |
    |----------------------+------------------------------|
    | Subject Contain Free | Subject Dosen't Contain Free |
    |----------------------+------------------------------|
    | Subject Contain Win  | Subject Dosen't Contain Win  |
    |----------------------+------------------------------|

    You will feed this data to your algorithm for Training Purpose, your code will learn and based on this, it will be able to make predictions in the future unlaneled dataset because it will know the rules of spam and ham emails.

 2. Unsupervised Machine Learning

    In unsupervised machine learning, training data is not labeled. So if we usethe last example, our training data will not be clearly marked as spam and ham. You will simply supply the data, your code will run on it and mark certain emails as Spam and Not Spam. You will evaluate it's performance and that's how it learns. This is usually used in case of business scenarios where you need to perform grouping or in case of this field, clustering. For example, let's say if you have a dataset of blood report of diabetic patient and you want to make certain groups. In this case you can simply create a algorithm which will create cluster of dataset with similar properties, let's say fasting blood level group with similar range.

 3. Reinforcement Machine Learning

    It is like carrot and stick approach where you train your code with rewards and punishment on each success and failure. So if they get their prediction right, they are rewarded and if they get their prediction wrong they are penalized. Self driving cars and chess playing bots are common example of this. This form of machine learning is required when there is a lot of uncertainty and software need to make real time decision.

* Hand's on R: Programming for Machine Learning and Data Science
** R - Introduction with Installation of R Studio
*** R Overview

- *R* Programming language is based on *S* language which was developed much earlier in 70's

- R Programming language was developed in 90's by *Ross Ihaka* and *Robert Gentleman* while working in the university of *Auckland*

- R is an open source *GNU* project

- Compatible with all major OS - MacOS, Linux, Unix, Windows, platforms

*** R Advantage

- Compatible with MacOS, Linux, Windows

- Free

- Not so steep learning curve to begin with

- Tons of packages for machine learning so our life becomes easy

- Still one of the most widely used language for machine learning

*** R Installation

- Step 1 - Download R - https://www.r-project.org/

- Step 2 - Download R Studio - https://www.rstudio.com/products/rstudio/download/

** Vectors, Matrix and Data Frame

Know the basic before jumping into it

*** Vector and Matrix

- Sample /(observations)/ size is 7 and there are 4 features /(variables)/. These 4 properties will be displayed in columns with 7 rows. First row will represent the name column.

|-------+----------+----------+----------+----------|
| *Name*  | *Feature1* | *Feature2* | *Feature3* | *Feature4* |
|-------+----------+----------+----------+----------|
| name1 |          |          |          |          |
|-------+----------+----------+----------+----------|
| name2 |          |          |          |          |
|-------+----------+----------+----------+----------|
| name3 |          |          |          |          |
|-------+----------+----------+----------+----------|
| name4 |          |          |          |          |
|-------+----------+----------+----------+----------|
| name5 |          |          |          |          |
|-------+----------+----------+----------+----------|
| name6 |          |          |          |          |
|-------+----------+----------+----------+----------|
| name7 |          |          |          |          |
|-------+----------+----------+----------+----------|

- Matrix can be represented by 7x5

- 7 Rows and 5 Columns

- Each row or column is a vector

- Entire dataset is a matrix. It is a multidimensional array (think of a spreadsheet), with multiple rows and columns

- representation: x_{j}^{i}

- i = serial/sequence number of sample

- j = serial/sequence number of dimension

- For matrix(X) - Capital letters are used, for vectors(x) - smallletters are used. But the concept remain same.

- So as in our example we have, 7 samples/observations, 4 features

- Therefore I can go upto 7 and I can go upto 4

- x_{3}^{4}: Here we are talking about 4^{th} sample out of 7 and 3^{rd }Feature or 3^{rd} column in the spreadsheet. It is the index value. So if the 36^{rd} column is "color", it means we are talking about color of 4^{th} sample.

- Row vectors are represented by [x_{3}_{}^{49 }+ x_{4}^{50}]

- Column vectors are represented by [x_{3}^{49}]
                                    [ + ]
                                    [x_{4}^{50}]

-

*** Data Frame

- Tabular data structure with rows and columns

- Data frame is a stastical concept

- Usually Matrix will have only 1 type of data like numeric, character etc.

- A data frame can have multiple data types so one column could me numerical whereas other could be character

** Data types in R

#+begin_src R :file 1.png :results file graphics
library(lattice)
xyplot(1:10 ~ 1:10)
#+end_src

#+RESULTS:
[[file:1.png]]

** Variables & Objects
** Vectors & Lists
** Data Wrangling with R
** Operators in R
** Loops in R

#+ATTR_HTML: :width 450px
[[file:img_5.png]]

** If Else in R
** Functions in R
* Assignment

1. How do you find more information about a function in R Studio?

2. How do you install packages in R Studio?

3. You need to load a excel file in R Studio, please write a compelete command to load it. Please note you will need to do something with the library in order to load it. You can use any name for your file.

4. Load the data set and save it as a matrix.

5. Write Command to find out the class of the Data.

6. Write few data types in R.

7. Create a variable with a number.

8. Create a String Variable.

9. Print variables created in last two questions.

10. Create two numerical vectors.

11. Create an object and multiply the 2 vectors created in last question.

12. Create a list with 5 elements in R.

13. Assign names to the elements in the List.

14. Access the 1^{st} and 4^{th} element in the list created in question 12.

15. Remove an element from the list created in question 12.

16. Load the data frame in R Studio. After loding the data set name the columns in data set.

17. Create a new object with a column and first 5000 rows selected from data frame created in question 16.

18. Create a vector and an if-else block such that else block is executed.

19. Create a for loop to print numbers upto 5.

20. Create a while loop till number 6

* Machine Learning Fundamentals
** Reading Various Kind's of Files with R
** Data Pre-Processing Introduction
*** R Base functions

- Use "$" sign to select variables

- Use "[row,column]" to select rows and columns

- If you leave blank row value and enter only column in above command, all the rows will be selected and vice versa. Or use subset.

- You can use following command to select and update a column/variable.

  #+begin_example
  dataframe$columnname = as.numeric/factor(dataframe$columnname)
  #+end_example

*** Merge

- merge(x,y,...)

- Where "x" and "y" are two seperate data frames

*** With function

- with

  #+begin_example
  a = mean(fb$Lifetime.Post.Total.Reach + fb$page.total.likes + fb$Lifetime.Post.Total.Impressions)
  a
  #+end_example

- Using with() we can clean this up

  #+begin_example
  a = with(fb, mean(Lifetime.Post.Total.Reach + page.total.likes + Lifetime.Post.Total.Impressions))
  a
  #+end_example

*** More functions to manage data

- order data

- sort data

- rbind & cbind

*** dplyr
**** Functions

- select: return a subset of the columns of a data frame

- filter: extract a subset of rows from a data frame based on logical conditions

- arrange: reorder rows of a data frame

- rename: rename variable in a data frame

- mutate: add new variables/columns or transform existing variables

- sumarise/sumarize: generate summary statistics of different variables in data frame

**** Arguments

- The first argument is a data frame

- The subsequent arguments describe what to do with it, and you can refer to columns in the data frame directly without using the "$" operator (just use the names).

- The result is a new data frame

- Data frames must be properly formatted and annotated for this

- to all be useful

**** library(dplry)

- Select Example: head(select(dataframe, column1:column-n))

- Filter Example:filter(select(dataframe, column1:column-n))

- Arrange: Reordering rows of a data frame (while preserving corrosponding order of other columns) is normally a pain to do in R

- Rename function

*** tidyr

- library(tidyr)

- gather(): takes multiple columns, and gathers them into key-value pairs (it makes wide data longer)

- spread(): takes two columns (key & value) and spreads in to multiple columns (it makes long data wider)

- seperate(): given either regular expression or a vector of character positions turns a single character column into multiple columns

- extract(): given a regular expression with capturing groups, it turns each group into a new column. If the groups don't match, or the input is NA, the output will be NA.

*** lubridate

- This package is used to handle dates like time zones, calculation realated to time.

- as.duration(x) example:

  #+begin_example
  library(lubridate)
  x <- interval(ymd("2018-01-01"),ymd("2018-09-18"))
  as.duration(x)

  [1] "22464000s (~37.14 weeks)"
  #+end_example

*** Important Functions

1. help() or ? followed by function name
2. example()
3. c(), scan()
4. seq()
5. rep()
6. data()
7. View()
8. Make.names()
9. str()
10. read.csv(), read.tables()
11. library(), require()
12. dim()
13. length()
14. ls()
15. rm() Removes an Item from memory
16. names() Lists names of variables in the data.frame

*** Handeling Different types of Data

1. as.interger()
2. as.numeric()
3. as.character()
4. as.data.frame()

*** Dealing with Missing values & NA's

1. Replace missing values with NA
2. Replace NA with mean, median or mode

*** Data source

- https://www.kaggle.com/c/titanic/data

* Data Visualization with R

Packages

1. Base Functions
2. GGPlot2
3. Lattice
4. Tabplot
5. Ploty
6. ScatterPlot3D

* Applied Ststistics for Machine Learning
Necessary EVIL ðŸ™‚

** Introduction to Applied Statistics with Variables and Sample Size

*** Variables

- In math a variable is a alphabetic character which represent a value

- Variables are also used in programming where they are used for almost similar purpose and contain/represent a value

- In data science, variables are measured, manipulated and explored to identify it's value or the output of an equation

- For example: BMI, weight etc.

*** Types of Variables

- *Nominal:* These are variables with two or more categories without any regard for ordering. For example, in polling data from a survey, the variable state, or candidate names. The number of states and candidates are definite and it doesn't matter what order of state or candidate name has no significance in it's relative importance in explaining the data.

- *Dichotomous:* A special case of nominal variables with exactly two categories such as gender, possible outcomes of a single coin toss, a survey questionnaire with a checkbox for telephone number as mobile or landline, or the outcome of election win or loss (assuming no tie).

- *Ordinal:* Just like nominal variables, we can have two or more categories in the ordinal variables with an added condition that the categories are ordered. For example, a customer rating for a movie in Netflix or a product in Amazon. The variable rating has a relative importance on a scale of 1 to 5, 1 being the lowest rating and 5 the highest for a movie or a product by a particular customer.

- *Continous Variables:* Continous variables are subdivided into Interval and Ratio:

  + Interval: The basic distinction is that they can be measured along a continous rnge and they have a numerical value. For exmple, the temperature in degrees Celsius or Fahrenheit is an interval variable. Note here that the temperature at 0â„ƒ is not the absolute zero, which simply means 0â„ƒ has certain degree of temperature measure than just saying the value means none or no measure.

  + Ratio: In contrast, ration variables include distance, mass, and height. Ratio reflects the fact that you can use the ration of measurements. So, for example, a distance of 10 meters is twice the distance if 5 meters. A value 0 for a ratio variable means a none or no measure.

*** Size of the Sample

- There is also one other important factor influencing variable and the outcome, and that is *"size of the sample"*. The smaller the size, higher the probablity of getting fake pattern whereas in bigger samples, chances of identifying a pattern closer to reality is *"high"*.

- Therefore it is important to pay attentation to the sample size in data science and carrying out any research project.

- If the sample size is small, the result will not be statistically significant.

** Descriptive vs Inferior Analysis

*** Descriptive Statistics/Analysis

It could be defined as the process of sumarizing data numerically to represent it in a compact and meaningful way where the representation help reader in understanding the broad overview of the data. It is used to represent the distribution pattern of a data. It is not based on probablity theory and it is solely used to read the data rather than deriving any forecasting from it.

Descriptive analysis is a quantitative study of the sample and use following values to summarize the data:

1. Mean
2. Standard Error
3. Mode
4. Standard Deviation
5. Sample Variance
6. Kurtosis
7. Skewness
8. Range
9. Minimum Value
10. Mazimum Value
11. Sum
12. Count

*** Inferential Analysis

As the term suggest, analysis to derive inferences from a data is called inferential analysis. Objective of Inferential Analysis is to produce actionable information which can be used to create business strategies by figuring out the relationship between variables, level and other factors involved in a study.

** Mean, Median, Mode and Range

*** Mean

- Mean is sum of all observations in a sample divided by the total number of observations

- Example:
  #+begin_example
  4,3,13,26
  Total Observations = 4
  Mean = (4+3+13+26)/4 = 11.5
  #+end_example

*** Median

- Median is the middle most observation when you arrange data in ascending order. Median is such that 50% of the observations are above the median and 50% of the observations are below the median

- Median for odd numbers = number of observation + 1/2 (the formula yields the serial number)

- Example:

  #+begin_example
  4,3,13,26,36
  Median = 5+1/2 = 3
  It means 3rd number (after organizing all the numbers in ascending order), in this case it is 13
  #+end_example

- If the numbers are even like in the given below example, we need to add 2 numbers in the middle and take the mean of them as median.

- Example:

  #+begin_example
  4,3,13,26
  In ascended order - 3,4,13,26
  Mean of 2 middle numbers = 4+13/2 = 8.5
  #+end_example

*** Mode

- Most frequent number in a given series is called mode.

- Example:

  #+begin_example
  1,3,5,3,9,12
  #+end_example

- 3 appears twice whereas other numbers appear only once, therefore it is mode.

*** Range

- Ranger is the difference between max and min value

- Example:

  #+begin_example
  1,3,5,3,9,12
  Range = 12-1 = 1
  #+end_example

** Variance and Standard Deviation

*** Variance

- It is squared difference from the mean or a number, add all the difference & calculate its mean. Note if you are taking a sample insted of population, you should use N-1.

|------------+--------------+--------------------|
| *Population* | *Value - Mean* | Variance (Squared) |
|------------+--------------+--------------------|
|         12 |         -4.8 |              23.04 |
|         14 |         -2.8 |               7.84 |
|         18 |          1.2 |               1.44 |
|         22 |          5.2 |              27.04 |
|         18 |          1.2 |               1.44 |
|------------+--------------+--------------------|
|       16.8 |              |               60.8 | Sum
|------------+--------------+--------------------|
|            |              |              12.16 | Variance
|            |              |        3.487119155 | Standard Deviation
|------------+--------------+--------------------|

- The smaller the variance, the closer the numbers are to the mean nand the larger the variance, the farther away the numbers are from the mean.

- In this table, add all the squared differences and calculate their mean

- Variance = 60.8/5 = 12/6

*** Standard Deviation

- It is the square root of variance and represented by sigma sign

- It represent the dispersion/spread of the sample

- It is the square root of variance

|--------+--------------+---------|
| *Sample* | *Value - Mean* | Squared |
|--------+--------------+---------|
|     12 |         -4.4 |   19.36 |
|     14 |         -2.8 |    7.84 |
|     18 |          1.2 |    1.44 |
|     22 |          5.2 |    27.4 |
|     18 |          1.2 |    1.44 |
|--------+--------------+---------|
|   16.8 |              |   57.12 | Sum
|        |              |    12.6 | Variance
|        |              |    3.48 | Standard Deviation
|--------+--------------+---------|

- Square root of 12.6 is 3.48 which is Standard Deviation

** Standard Error, Skewness with Kurtosis

*** Standard Error

- Sample Statistic = mean

- Standard deviation of the sample statistic is called standard error

- Several means can be calculated for several samples and their distribution is called sampling distribution of the sampling mean

- Standard error is the ratio of standard deviation and square root of the sample size

- For example: in the class of 60, you take a sample of 4

- Mean is 10 marks

- Standard deviation is 8

- Standard error for sampling distribution would be 8/square root of 4

- 8/sqrt(4)

*** Skewness

- Skewness is the measure of the asymmetry or deviation from the symmetry in statistical analysis. It is basically used to represent the difference between mean and median. Skewness is usually divided into positive and negative skewness.

- *Positive Skewness*: When there are more values at positive side (right side) in a curved graph, it is called as positive skewed or right skewed.

- *Negative Skewness*: When there are more values at negative side (left side) in a curved graph, it is called as negative skewed or left skewed.

*** Kurtosis

- kurtosis is used to represent the *"Peakness"* of a distribution in probability. Kurtosis has following characteristics:

  + High Kurtosis: tall peak, rapid decline in the tails
  + Low Kurtosis: flat peaks, gradual decline in the tails
  + Extreme case: uniform distribution

** P Value with Confidence Interval

*** Normal Distribution

#+ATTR_HTML: :width 750px
[[file:img_6.png]]

*** Central Limit Theorem

- Irrespective of the nature of the distribution of the original population (right skewed or left skewed), the distribution of the sample will be a normal distribution as the size of the sample goes up

- Recomended number is 30

#+ATTR_HTML: :width 750px
[[file:img_7.png]]

*** Confidence Level

- Confidence Interval is a interval value used to represent the interval for a population parameter where a sample will have high probably of having that parameter of interest based on sample data. Confidence Interval is a type of Interval Estimation Techniques.

- Confidence Interval is used to represent the probability and is expressed in precentage.

- *Interval estimation* is the technique of using data to estimate an interval of probable values of an unknown population parameter.

- *For example*: There is a population or data where value of a parameter is not known. If you conduct repeated sampling and conduct experiments using same procedure, certain value of intervals will contain the unknown parameter. If you conduct 100 test and 95 of them were found to contain the unknown parameter, your confidence interval will be 95%.

- Confidence interval = sample statistic + Margin of error

- where

- Maargine of error = Critical value * Standard error of statistic

**** How to Construct Confidence Level

- Select a statistic that will be used to estimate a population parameter. We can use p value

- Select a confidence level

- Find the margin of error

#+ATTR_HTML: :width 750px
[[file:img_8.png]]

*** p-Value

- p-Value in statistic is used to measure the significance of results.

- p-Value is the number which is measured to gauge the strength of the data. Conclusions are made based on the following output

- P value less than 5% (0.05%) indicates higher statistical significance and approve rejection of null hypothesis which simply means that variable are strongly related to each other and final output.

- P value more that 5% (0.05&) indicates lower statistical significance and support null hypothesis.

- P value close to 5% is considered borderline.

** T test and F ratio

There are two types

*** T Test for dependent samples

- It is also known as *"Matched-Pairs t Test"*. It compares the mean of two samples which are related to each other. It is used when same sample could be used or tested under two conditions which are inter-related. For example, a group of persons undergoing machine learning training at a training center and then appering for exam. You can test the knowledge score of same group at the beining of the training and after training. Exams score to measure the difference in their skills due to the training course.

*** T Test for independent samples

- It is one of the most widely used statistical calculation concept. It is primarily used to determine the difference between means for two groups.

- Now if we use the example mentioned under *"T Test for Dependent Sample"*, we can use the two randomly selected group from two different training institute preparing for machine learning and evaluate the difference in the mean of their scores after test.

*** T Test
Few important points

- Few important factors to mention here are

- Size of the sample (with bigger data more accuracy)

- Difference between means of groups should be big enpugh to indicte a substantial trend

- Average performance of the individuals is closer to the mean of their respective groups

- You should use one tailed test when you expect only one group's mean to change or when you expect changes to happen only in one direction whereas when you expect changes to move in any direction or any group can move either direction (up or down), you should use ywo tail t test.

*** F Test

- It is test where distribution is F shaped. It is commonly used in ANOVA when means of the two population, having similar standard deviation, are equal.

- Critical value is selected using the f table and then it is used to accept or reject the null hypothesis

- F values are non-negative, distribution is asymmetric and two independent degrees of freedom, one for numerator and one for denominator.

** Hypothesis Testing
*** Types of Hypothesis

- *Null Hypothesis*: Null hypothesis simply means that there is no relation between the two variable and data scientist use it to disapprove and reject a theory.

- For example, if a ecommerce portal propose a theory that sales are up during a particular time in the year, null hypothesis will suggest that *"sales are not up during that time of year or time is not significant and has to nothing with the rising sales"*.

- Null Hypothesis is represented by H_{0}

- Null Hypothesis implies that an event is not due to any impact of the variable but, due to PURE CHANGE

*** Alternative Hypothesis

- Alternative hypothesis is the exact opposite of the null hypothesis. SO if we go back to our last example about sales in particular time of the year.

- Alternative hypothesis will suggest that particular time is responsible for the increase in sale.

*** Hypothesis Testing

- You run various algorithms like Naive Bayes, KNN etc to accept or reject null hypothesis.

- Usually if the p value is less than critical value or value of significance, you reject the null hypothesis

* Machine Learning Fundamentals

** Machine Learning Models

- Regression (Suprevised Learning)
- Classification (Supervised Learning)
- Clustering (Unsupervised Learning)

*** Steps to Create ML Model

1. Data procurement/gathering
2. Data modification/cleaning
3. Model selection
4. Training
5. Evaluation
6. Prediction

** Regression

- Algorithm produces continous variables.

- It is used to relate independent (predictor) & dependent (target) variables

- In regression inputs are called predictor variable, explanatory variables, regressors

- Dependent variable is dependent, explained variable or regressand

- Predictors are used to produce an output which is continous response variable

- A best fitted line is drawn which minimizes the distance between various points

*** Types of Regression

1. Linear Regression
2. Logistic Regression
3. Polynomial Regression

*** Applications

1. Sales Forecasting
2. Demand supply forecasting
3. Operation's cost optimization
4. Insurance industry - claim predication
5. Banking
6. Healthcare industry - cost prediction

** Classification

- Classification algorithm are used for categorical variables for example spam or Not spam (ham)

- In classification, you classify things based on the shared features or properties

- It can also be used for more advance classifications like image classification

- Please note if your ML model is not trained on something, it won't work on it. For example : if your model has been trained on hand written numbers, it won't work on alphabets

*** Types of Classification

1. Naive Bayes
2. KNN
3. Artificial Neural Network (ANN)
4. Support Vector Machines (SVN)
5. Random forest, CART (decision trees)

*** Applications

1. Cancer detection
2. Email spam detection
3. Marketing campaigns to determine conversion rate

** Clustering

- Unsupervised Machine Learning technique

- Clustering is done to group similar objects or data points

- it creates segment with similar data points

- Data points in each clusters are different to other clusters in the same data set

- Clustering helps by reducing a large data sets into few clusters

*** Grouping in Clustering

1. Euclidian distance (most common): sqrt(6^{2} + 4^{2}) = 7.211103
2. Chebyshey Distance: Max(6,4) = 6
3. Manhattan Distance: 6+4=10

*** Types of Clustering

1. Hierarchical
2. Partition
3. Agglomerative
4. K-Means

*** Dimension Reduction

- Dimension reduction is needed if there are too many variables
- Variables are reduced by reducing the unnecessary variables
- It's like feature selection
- It improves the time required for training a model
- It improves the model performance by reducing the redundancies

*** Dimension Reduction Techniques

1. Principal Componenet Analysis
2. Factor Analysis

* ANOVA with R

- Analysis of Variance which is also known as ANOVA, is the statistical model which is used to measure the significant variation between groups of variables where usually means are used to measure the difference. It basically inform user about the difference in the mean of multiple groups for statistical significance.

- ANOVA was developed by R.A.Fisher

- The dependent variable is the variable of interest & it is continous variable

- The treatment variable is the independent variable and it is a categorical variable

** Types of ANOVA

1. One way ANOVA
2. Two way ANOVA

** Asumption of ANOVA

- Dependent variable are normally distributed and have same variance
- Errors are normally distributed and are independent

** ANOVA

- When you have more than 2 groups, you use ANOVA
- t-test and z-test are similar tests
- Test equlity of the means for more than 2 population/sample/group
- If you were to use t-test or z-test for pairwise combination, probability of *type 1 error* goes up

** Classification Error

- Type-1 error: False Positive = rejection of true null hypothesis

- Type-2 error: False Negative = Failure to reject null hypothesis

- Example: Ran a ML model to detect cancer patient

|------+---------------+---------------+----------------+----------------|
| Name | True Positive | True Negative | False Positive | False Negative |
|------+---------------+---------------+----------------+----------------|
| A    | Y             | N             | N              | N              |
| B    | N             | Y             | N              | N              |
| C    | N             | N             | Y              | N              |
| D    | N             | N             | N              | Y              |
|------+---------------+---------------+----------------+----------------|

** ANOVA

- ANOVA is governed by f-stats. ANOVA simply tells that there is difference in mean in the groups, it doesn't tell where is the difference. To know where is the difference, we perform post-hoc test

- Example of application:

  + Effect of socioeconomic status (SES) and gender on body mass index of kids in the age range of 6-10 years

  + Whether a new drug influences the cure rate of a disease

  + Effect of a vitamin c on common cold among school children

** 2 way ANOVA Types

- Two way ANOVA with replication

- Two way anova without replication

- For example, we ran a survey on weekdays in 5 stores. If the survey was only performed once a day, it will be two way anova without replication. But if the survey was repeated few times everyday like noon, evening etc, it will be two way ANOVA with replication

- Important point in 2 way ANOVA is interaction effect. Suppose there is a sample, few are having diabetes and few are having hypertension and then there is a third group with both-diabetes & hypertension. If we are asuming the probablity of these 3 groups towards cardiac problem like heart attack, probability will be highest in third group due to cumulative effect.

- So let's say patients with diabetes, their probability is 0.3

- Group II with hypertension, their probability is 0.4

- Group III with both will have probability 0.9 (more than compined) due to interaction effect

** Steps to conduct ANOVA

1. Identify the independent variable and dependent variable
2. Test for assumption
3. Decompose the total variation into between group variable and within group variation

** Abrivation in ANOVA

1. SS = Sum of squares
2. DF = degrees of freedom
3. MS = mean square
4. F ststs = F statistics, between group variance / within group variance
5. P value (actual significance level)
6. F-cric = F critical

** Steps to conduct ANOVA in R

1. Use summary & str functions to look in the data
2. Identify all the variables you need for analysis
3. Use visualization to get better insight
4. Perform normalcy test using cat and cat(shapiro.test)
5. Perform leveneTest
6. Perform Bartlett.test
7. aov command to run anova: aov(dependent variable, independent variable)
8. Post hoc test - TukeyHSD(aov1)

* Linear Regression with R
* Logistic Regression with R
* Dimension Reduction Technique
* Clustering with K-Means
* Tree based models - CART & Random Forest
* KNN - K Nearest Model
* Naive Bayes
* Neural Networks with R
